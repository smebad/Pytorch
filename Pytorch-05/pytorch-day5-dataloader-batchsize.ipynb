{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping of the unnecessary columns\n",
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train testv split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling for features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54558153,  0.34178673,  0.63600831, ...,  1.35585735,\n",
       "         1.27223712,  1.596594  ],\n",
       "       [ 2.49868398,  1.83923256,  2.45108115, ...,  2.12642998,\n",
       "         0.31745638,  0.12994989],\n",
       "       [-0.07786642, -0.72237588, -0.14679183, ..., -0.89273285,\n",
       "        -0.85583141, -0.70629925],\n",
       "       ...,\n",
       "       [ 2.09592556,  0.41558772,  2.20320777, ...,  1.01206341,\n",
       "        -0.11005739,  0.22672808],\n",
       "       [-0.90821083,  0.53224089, -0.94678319, ..., -1.71606006,\n",
       "        -0.70382651, -0.98487074],\n",
       "       [ 0.38006438,  3.4080987 ,  0.46009816, ...,  1.268427  ,\n",
       "         0.96506056,  1.92809942]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17     M\n",
       "236    M\n",
       "357    B\n",
       "184    M\n",
       "28     M\n",
       "      ..\n",
       "330    M\n",
       "83     M\n",
       "272    M\n",
       "550    B\n",
       "259    M\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding for target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  # constructor\n",
    "\n",
    "  # inherits from Dataset class\n",
    "  def __init__(self, features, labels):\n",
    "\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    \n",
    "  # returns the number of samples in the dataset\n",
    "  def __len__(self):\n",
    "\n",
    "    return self.features.shape[0]\n",
    "  \n",
    "  # gets a sample from the dataset\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.3123, -0.5529, -1.2783, -1.0745, -0.8432, -0.2751, -0.0976, -0.6948,\n",
       "          0.8576,  1.1525, -0.7849, -0.5143, -0.7112, -0.6057, -0.3551,  0.4650,\n",
       "          0.5374, -0.5758, -0.3714,  0.0489, -1.1658, -0.4176, -1.0997, -0.9348,\n",
       "         -0.4116,  0.5228,  0.7300, -0.5480,  0.1197,  0.7676]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crating data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model architecture\n",
    "class NN(nn.Module):\n",
    "\n",
    "  # creating constructor\n",
    "  def __init__(self, num_features):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(num_features, 1) # single neuron\n",
    "    self.sigmoid = nn.Sigmoid() # activation function\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self, features):\n",
    "    out = self.linear(features)\n",
    "    out = self.sigmoid(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Parameters\n",
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling loss function from Pytorch.nn\n",
    "loss_function = nn.BCELoss() # binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all tensors to float32 (fixes dtype mismatch issue)\n",
    "X_train_tensor = X_train_tensor.to(torch.float32)\n",
    "X_test_tensor = X_test_tensor.to(torch.float32)\n",
    "y_train_tensor = y_train_tensor.to(torch.float32)\n",
    "y_test_tensor = y_test_tensor.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5662342309951782\n",
      "Epoch: 2, Loss: 0.4730672240257263\n",
      "Epoch: 3, Loss: 0.41433414816856384\n",
      "Epoch: 4, Loss: 0.37337347865104675\n",
      "Epoch: 5, Loss: 0.34282585978507996\n",
      "Epoch: 6, Loss: 0.3189491331577301\n",
      "Epoch: 7, Loss: 0.29963219165802\n",
      "Epoch: 8, Loss: 0.28358879685401917\n",
      "Epoch: 9, Loss: 0.2699875831604004\n",
      "Epoch: 10, Loss: 0.25826552510261536\n",
      "Epoch: 11, Loss: 0.24802649021148682\n",
      "Epoch: 12, Loss: 0.23898299038410187\n",
      "Epoch: 13, Loss: 0.230920672416687\n",
      "Epoch: 14, Loss: 0.22367604076862335\n",
      "Epoch: 15, Loss: 0.2171219140291214\n",
      "Epoch: 16, Loss: 0.2111576646566391\n",
      "Epoch: 17, Loss: 0.2057022750377655\n",
      "Epoch: 18, Loss: 0.20068980753421783\n",
      "Epoch: 19, Loss: 0.196065753698349\n",
      "Epoch: 20, Loss: 0.19178465008735657\n",
      "Epoch: 21, Loss: 0.18780812621116638\n",
      "Epoch: 22, Loss: 0.1841035634279251\n",
      "Epoch: 23, Loss: 0.1806429624557495\n",
      "Epoch: 24, Loss: 0.17740210890769958\n",
      "Epoch: 25, Loss: 0.17435996234416962\n"
     ]
    }
   ],
   "source": [
    "# Training pipeline by creating a model\n",
    "model = NN(X_train_tensor.shape[1])\n",
    "\n",
    "# defining optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # for weights update\n",
    "\n",
    "# defining loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  # forward pass\n",
    "  y_pred = model(X_train_tensor)\n",
    "\n",
    "  # loss calculation\n",
    "  loss = loss_function(y_pred, y_train_tensor.view(-1, 1)) # BCELoss\n",
    "  \n",
    "  \n",
    "  # zero gradients\n",
    "  optimizer.zero_grad() # reset gradients\n",
    "\n",
    "  # backward pass\n",
    "  loss.backward()\n",
    "\n",
    "  #  parameter update\n",
    "  optimizer.step() # update weights\n",
    "\n",
    "  # zero gradients\n",
    "  model.linear.weight.grad.zero_()\n",
    "  model.linear.bias.grad.zero_()\n",
    "\n",
    "  # printing loss\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.26652687788009644\n",
      "Epoch: 1, Loss: 0.14996136724948883\n",
      "Epoch: 1, Loss: 0.08915184438228607\n",
      "Epoch: 1, Loss: 0.21076834201812744\n",
      "Epoch: 1, Loss: 0.12370183318853378\n",
      "Epoch: 1, Loss: 0.1475113183259964\n",
      "Epoch: 1, Loss: 0.18512603640556335\n",
      "Epoch: 1, Loss: 0.21626272797584534\n",
      "Epoch: 1, Loss: 0.13739071786403656\n",
      "Epoch: 1, Loss: 0.13061213493347168\n",
      "Epoch: 1, Loss: 0.16008611023426056\n",
      "Epoch: 1, Loss: 0.1287924349308014\n",
      "Epoch: 1, Loss: 0.15186132490634918\n",
      "Epoch: 1, Loss: 0.14848043024539948\n",
      "Epoch: 1, Loss: 0.026309428736567497\n",
      "Epoch: 2, Loss: 0.13826222717761993\n",
      "Epoch: 2, Loss: 0.17157159745693207\n",
      "Epoch: 2, Loss: 0.08943293988704681\n",
      "Epoch: 2, Loss: 0.06233600527048111\n",
      "Epoch: 2, Loss: 0.1765890121459961\n",
      "Epoch: 2, Loss: 0.14231185615062714\n",
      "Epoch: 2, Loss: 0.09229631721973419\n",
      "Epoch: 2, Loss: 0.1954343020915985\n",
      "Epoch: 2, Loss: 0.1273755133152008\n",
      "Epoch: 2, Loss: 0.16555719077587128\n",
      "Epoch: 2, Loss: 0.14986552298069\n",
      "Epoch: 2, Loss: 0.13366523385047913\n",
      "Epoch: 2, Loss: 0.10666371881961823\n",
      "Epoch: 2, Loss: 0.15760381519794464\n",
      "Epoch: 2, Loss: 0.09412062168121338\n",
      "Epoch: 3, Loss: 0.09251182526350021\n",
      "Epoch: 3, Loss: 0.13730479776859283\n",
      "Epoch: 3, Loss: 0.1416480541229248\n",
      "Epoch: 3, Loss: 0.14152103662490845\n",
      "Epoch: 3, Loss: 0.11205087602138519\n",
      "Epoch: 3, Loss: 0.1767546683549881\n",
      "Epoch: 3, Loss: 0.11070236563682556\n",
      "Epoch: 3, Loss: 0.09214866161346436\n",
      "Epoch: 3, Loss: 0.11190645396709442\n",
      "Epoch: 3, Loss: 0.11926589906215668\n",
      "Epoch: 3, Loss: 0.11647538840770721\n",
      "Epoch: 3, Loss: 0.12570859491825104\n",
      "Epoch: 3, Loss: 0.1639682650566101\n",
      "Epoch: 3, Loss: 0.06375087052583694\n",
      "Epoch: 3, Loss: 0.1571917086839676\n",
      "Epoch: 4, Loss: 0.09560519456863403\n",
      "Epoch: 4, Loss: 0.10007316619157791\n",
      "Epoch: 4, Loss: 0.08338192105293274\n",
      "Epoch: 4, Loss: 0.07299698144197464\n",
      "Epoch: 4, Loss: 0.0720299780368805\n",
      "Epoch: 4, Loss: 0.11425076425075531\n",
      "Epoch: 4, Loss: 0.07268857955932617\n",
      "Epoch: 4, Loss: 0.2021910399198532\n",
      "Epoch: 4, Loss: 0.09079837054014206\n",
      "Epoch: 4, Loss: 0.17679202556610107\n",
      "Epoch: 4, Loss: 0.1748896688222885\n",
      "Epoch: 4, Loss: 0.16222907602787018\n",
      "Epoch: 4, Loss: 0.07704242318868637\n",
      "Epoch: 4, Loss: 0.10431340336799622\n",
      "Epoch: 4, Loss: 0.04444601386785507\n",
      "Epoch: 5, Loss: 0.10193835198879242\n",
      "Epoch: 5, Loss: 0.13926704227924347\n",
      "Epoch: 5, Loss: 0.07122345268726349\n",
      "Epoch: 5, Loss: 0.08002517372369766\n",
      "Epoch: 5, Loss: 0.15187028050422668\n",
      "Epoch: 5, Loss: 0.09576527029275894\n",
      "Epoch: 5, Loss: 0.11541733890771866\n",
      "Epoch: 5, Loss: 0.16205865144729614\n",
      "Epoch: 5, Loss: 0.09173344075679779\n",
      "Epoch: 5, Loss: 0.09166812896728516\n",
      "Epoch: 5, Loss: 0.11764584481716156\n",
      "Epoch: 5, Loss: 0.11498694121837616\n",
      "Epoch: 5, Loss: 0.10642004758119583\n",
      "Epoch: 5, Loss: 0.0538317933678627\n",
      "Epoch: 5, Loss: 0.08187603950500488\n",
      "Epoch: 6, Loss: 0.11521972715854645\n",
      "Epoch: 6, Loss: 0.09171296656131744\n",
      "Epoch: 6, Loss: 0.02378423511981964\n",
      "Epoch: 6, Loss: 0.09729083627462387\n",
      "Epoch: 6, Loss: 0.08857302367687225\n",
      "Epoch: 6, Loss: 0.18103863298892975\n",
      "Epoch: 6, Loss: 0.07756267488002777\n",
      "Epoch: 6, Loss: 0.15274013578891754\n",
      "Epoch: 6, Loss: 0.08133206516504288\n",
      "Epoch: 6, Loss: 0.20127791166305542\n",
      "Epoch: 6, Loss: 0.046493858098983765\n",
      "Epoch: 6, Loss: 0.06295295804738998\n",
      "Epoch: 6, Loss: 0.1083427220582962\n",
      "Epoch: 6, Loss: 0.10262495279312134\n",
      "Epoch: 6, Loss: 0.030764490365982056\n",
      "Epoch: 7, Loss: 0.08585191518068314\n",
      "Epoch: 7, Loss: 0.10158981382846832\n",
      "Epoch: 7, Loss: 0.12295955419540405\n",
      "Epoch: 7, Loss: 0.09105309844017029\n",
      "Epoch: 7, Loss: 0.12090905755758286\n",
      "Epoch: 7, Loss: 0.08803900331258774\n",
      "Epoch: 7, Loss: 0.07555100321769714\n",
      "Epoch: 7, Loss: 0.04923621192574501\n",
      "Epoch: 7, Loss: 0.17077837884426117\n",
      "Epoch: 7, Loss: 0.12486672401428223\n",
      "Epoch: 7, Loss: 0.06500798463821411\n",
      "Epoch: 7, Loss: 0.08873889595270157\n",
      "Epoch: 7, Loss: 0.0876741111278534\n",
      "Epoch: 7, Loss: 0.09097693860530853\n",
      "Epoch: 7, Loss: 0.07743684947490692\n",
      "Epoch: 8, Loss: 0.11005309969186783\n",
      "Epoch: 8, Loss: 0.056462567299604416\n",
      "Epoch: 8, Loss: 0.07832875847816467\n",
      "Epoch: 8, Loss: 0.08397354185581207\n",
      "Epoch: 8, Loss: 0.0810977965593338\n",
      "Epoch: 8, Loss: 0.15258198976516724\n",
      "Epoch: 8, Loss: 0.06679338961839676\n",
      "Epoch: 8, Loss: 0.11068251729011536\n",
      "Epoch: 8, Loss: 0.07957304269075394\n",
      "Epoch: 8, Loss: 0.10750963538885117\n",
      "Epoch: 8, Loss: 0.15322470664978027\n",
      "Epoch: 8, Loss: 0.055902332067489624\n",
      "Epoch: 8, Loss: 0.07037464529275894\n",
      "Epoch: 8, Loss: 0.06094782054424286\n",
      "Epoch: 8, Loss: 0.3117799460887909\n",
      "Epoch: 9, Loss: 0.08818873763084412\n",
      "Epoch: 9, Loss: 0.030013980343937874\n",
      "Epoch: 9, Loss: 0.13332924246788025\n",
      "Epoch: 9, Loss: 0.08784650266170502\n",
      "Epoch: 9, Loss: 0.1263560950756073\n",
      "Epoch: 9, Loss: 0.15738710761070251\n",
      "Epoch: 9, Loss: 0.044602811336517334\n",
      "Epoch: 9, Loss: 0.05104006826877594\n",
      "Epoch: 9, Loss: 0.16863541305065155\n",
      "Epoch: 9, Loss: 0.06203009933233261\n",
      "Epoch: 9, Loss: 0.06286276876926422\n",
      "Epoch: 9, Loss: 0.08000075072050095\n",
      "Epoch: 9, Loss: 0.08213609457015991\n",
      "Epoch: 9, Loss: 0.10981214046478271\n",
      "Epoch: 9, Loss: 0.05169608071446419\n",
      "Epoch: 10, Loss: 0.06915514171123505\n",
      "Epoch: 10, Loss: 0.13534463942050934\n",
      "Epoch: 10, Loss: 0.053421370685100555\n",
      "Epoch: 10, Loss: 0.1244458556175232\n",
      "Epoch: 10, Loss: 0.09081190824508667\n",
      "Epoch: 10, Loss: 0.07361209392547607\n",
      "Epoch: 10, Loss: 0.06630358844995499\n",
      "Epoch: 10, Loss: 0.15907883644104004\n",
      "Epoch: 10, Loss: 0.06365815550088882\n",
      "Epoch: 10, Loss: 0.09435348212718964\n",
      "Epoch: 10, Loss: 0.05236143618822098\n",
      "Epoch: 10, Loss: 0.07691188156604767\n",
      "Epoch: 10, Loss: 0.0935412347316742\n",
      "Epoch: 10, Loss: 0.09240905195474625\n",
      "Epoch: 10, Loss: 0.07140972465276718\n",
      "Epoch: 11, Loss: 0.1346108615398407\n",
      "Epoch: 11, Loss: 0.03068583831191063\n",
      "Epoch: 11, Loss: 0.05650513246655464\n",
      "Epoch: 11, Loss: 0.13049842417240143\n",
      "Epoch: 11, Loss: 0.08580832928419113\n",
      "Epoch: 11, Loss: 0.10015016049146652\n",
      "Epoch: 11, Loss: 0.07355741411447525\n",
      "Epoch: 11, Loss: 0.05679364874958992\n",
      "Epoch: 11, Loss: 0.15846054255962372\n",
      "Epoch: 11, Loss: 0.09435690194368362\n",
      "Epoch: 11, Loss: 0.03305909037590027\n",
      "Epoch: 11, Loss: 0.05925406515598297\n",
      "Epoch: 11, Loss: 0.049723070114851\n",
      "Epoch: 11, Loss: 0.13810710608959198\n",
      "Epoch: 11, Loss: 0.11458680778741837\n",
      "Epoch: 12, Loss: 0.10564461350440979\n",
      "Epoch: 12, Loss: 0.06537791341543198\n",
      "Epoch: 12, Loss: 0.08065322786569595\n",
      "Epoch: 12, Loss: 0.06318721920251846\n",
      "Epoch: 12, Loss: 0.19020044803619385\n",
      "Epoch: 12, Loss: 0.08262571692466736\n",
      "Epoch: 12, Loss: 0.058352552354335785\n",
      "Epoch: 12, Loss: 0.0758339911699295\n",
      "Epoch: 12, Loss: 0.045083291828632355\n",
      "Epoch: 12, Loss: 0.06958819180727005\n",
      "Epoch: 12, Loss: 0.07558751106262207\n",
      "Epoch: 12, Loss: 0.14361977577209473\n",
      "Epoch: 12, Loss: 0.07496721297502518\n",
      "Epoch: 12, Loss: 0.05982094630599022\n",
      "Epoch: 12, Loss: 0.033614154905080795\n",
      "Epoch: 13, Loss: 0.16503554582595825\n",
      "Epoch: 13, Loss: 0.10797388851642609\n",
      "Epoch: 13, Loss: 0.06426046788692474\n",
      "Epoch: 13, Loss: 0.038071759045124054\n",
      "Epoch: 13, Loss: 0.06169192120432854\n",
      "Epoch: 13, Loss: 0.06175602599978447\n",
      "Epoch: 13, Loss: 0.05010126158595085\n",
      "Epoch: 13, Loss: 0.1259555071592331\n",
      "Epoch: 13, Loss: 0.11518064141273499\n",
      "Epoch: 13, Loss: 0.0519896037876606\n",
      "Epoch: 13, Loss: 0.03481611981987953\n",
      "Epoch: 13, Loss: 0.06517156213521957\n",
      "Epoch: 13, Loss: 0.11877602338790894\n",
      "Epoch: 13, Loss: 0.08235464245080948\n",
      "Epoch: 13, Loss: 0.13360963761806488\n",
      "Epoch: 14, Loss: 0.08025329560041428\n",
      "Epoch: 14, Loss: 0.041064564138650894\n",
      "Epoch: 14, Loss: 0.08526992797851562\n",
      "Epoch: 14, Loss: 0.08767502754926682\n",
      "Epoch: 14, Loss: 0.10707069933414459\n",
      "Epoch: 14, Loss: 0.08110370486974716\n",
      "Epoch: 14, Loss: 0.07605499029159546\n",
      "Epoch: 14, Loss: 0.041255299001932144\n",
      "Epoch: 14, Loss: 0.07253517210483551\n",
      "Epoch: 14, Loss: 0.07312886416912079\n",
      "Epoch: 14, Loss: 0.05879432335495949\n",
      "Epoch: 14, Loss: 0.07452504336833954\n",
      "Epoch: 14, Loss: 0.11002150177955627\n",
      "Epoch: 14, Loss: 0.13965442776679993\n",
      "Epoch: 14, Loss: 0.0955001711845398\n",
      "Epoch: 15, Loss: 0.08864542096853256\n",
      "Epoch: 15, Loss: 0.029896624386310577\n",
      "Epoch: 15, Loss: 0.052595846354961395\n",
      "Epoch: 15, Loss: 0.19023290276527405\n",
      "Epoch: 15, Loss: 0.06564807891845703\n",
      "Epoch: 15, Loss: 0.051059458404779434\n",
      "Epoch: 15, Loss: 0.13880997896194458\n",
      "Epoch: 15, Loss: 0.04457937553524971\n",
      "Epoch: 15, Loss: 0.04810047522187233\n",
      "Epoch: 15, Loss: 0.1158580556511879\n",
      "Epoch: 15, Loss: 0.08998975157737732\n",
      "Epoch: 15, Loss: 0.048537105321884155\n",
      "Epoch: 15, Loss: 0.06618380546569824\n",
      "Epoch: 15, Loss: 0.08436781167984009\n",
      "Epoch: 15, Loss: 0.06977549940347672\n",
      "Epoch: 16, Loss: 0.14230817556381226\n",
      "Epoch: 16, Loss: 0.039932023733854294\n",
      "Epoch: 16, Loss: 0.11141755431890488\n",
      "Epoch: 16, Loss: 0.05743883550167084\n",
      "Epoch: 16, Loss: 0.03435112163424492\n",
      "Epoch: 16, Loss: 0.09482261538505554\n",
      "Epoch: 16, Loss: 0.0809248760342598\n",
      "Epoch: 16, Loss: 0.06198956072330475\n",
      "Epoch: 16, Loss: 0.048364102840423584\n",
      "Epoch: 16, Loss: 0.11165398359298706\n",
      "Epoch: 16, Loss: 0.059883542358875275\n",
      "Epoch: 16, Loss: 0.09472324699163437\n",
      "Epoch: 16, Loss: 0.06738106906414032\n",
      "Epoch: 16, Loss: 0.079137422144413\n",
      "Epoch: 16, Loss: 0.1126619428396225\n",
      "Epoch: 17, Loss: 0.1348601132631302\n",
      "Epoch: 17, Loss: 0.09232626855373383\n",
      "Epoch: 17, Loss: 0.11079912632703781\n",
      "Epoch: 17, Loss: 0.03138713538646698\n",
      "Epoch: 17, Loss: 0.06472152471542358\n",
      "Epoch: 17, Loss: 0.04960703104734421\n",
      "Epoch: 17, Loss: 0.04546218365430832\n",
      "Epoch: 17, Loss: 0.08339256048202515\n",
      "Epoch: 17, Loss: 0.08393552154302597\n",
      "Epoch: 17, Loss: 0.0800248384475708\n",
      "Epoch: 17, Loss: 0.08357185125350952\n",
      "Epoch: 17, Loss: 0.07668839395046234\n",
      "Epoch: 17, Loss: 0.07580608874559402\n",
      "Epoch: 17, Loss: 0.07597967982292175\n",
      "Epoch: 17, Loss: 0.022220391780138016\n",
      "Epoch: 18, Loss: 0.10226161032915115\n",
      "Epoch: 18, Loss: 0.07920819520950317\n",
      "Epoch: 18, Loss: 0.0662640854716301\n",
      "Epoch: 18, Loss: 0.10185562074184418\n",
      "Epoch: 18, Loss: 0.06631120294332504\n",
      "Epoch: 18, Loss: 0.15748576819896698\n",
      "Epoch: 18, Loss: 0.03087899088859558\n",
      "Epoch: 18, Loss: 0.07854925096035004\n",
      "Epoch: 18, Loss: 0.03826838359236717\n",
      "Epoch: 18, Loss: 0.03210465982556343\n",
      "Epoch: 18, Loss: 0.10314248502254486\n",
      "Epoch: 18, Loss: 0.09691103547811508\n",
      "Epoch: 18, Loss: 0.04735426604747772\n",
      "Epoch: 18, Loss: 0.05938605219125748\n",
      "Epoch: 18, Loss: 0.07387476414442062\n",
      "Epoch: 19, Loss: 0.09347844868898392\n",
      "Epoch: 19, Loss: 0.06092850863933563\n",
      "Epoch: 19, Loss: 0.032819345593452454\n",
      "Epoch: 19, Loss: 0.06584709882736206\n",
      "Epoch: 19, Loss: 0.03530111163854599\n",
      "Epoch: 19, Loss: 0.1044069305062294\n",
      "Epoch: 19, Loss: 0.06541354954242706\n",
      "Epoch: 19, Loss: 0.026222646236419678\n",
      "Epoch: 19, Loss: 0.18765024840831757\n",
      "Epoch: 19, Loss: 0.04982222616672516\n",
      "Epoch: 19, Loss: 0.06638174504041672\n",
      "Epoch: 19, Loss: 0.03847214952111244\n",
      "Epoch: 19, Loss: 0.06862840801477432\n",
      "Epoch: 19, Loss: 0.13516183197498322\n",
      "Epoch: 19, Loss: 0.14675378799438477\n",
      "Epoch: 20, Loss: 0.06979552656412125\n",
      "Epoch: 20, Loss: 0.03892366588115692\n",
      "Epoch: 20, Loss: 0.0874989852309227\n",
      "Epoch: 20, Loss: 0.07066698372364044\n",
      "Epoch: 20, Loss: 0.16986149549484253\n",
      "Epoch: 20, Loss: 0.030474957078695297\n",
      "Epoch: 20, Loss: 0.06247325986623764\n",
      "Epoch: 20, Loss: 0.0910467728972435\n",
      "Epoch: 20, Loss: 0.06096364185214043\n",
      "Epoch: 20, Loss: 0.05388062074780464\n",
      "Epoch: 20, Loss: 0.023297103121876717\n",
      "Epoch: 20, Loss: 0.07371866703033447\n",
      "Epoch: 20, Loss: 0.11217072606086731\n",
      "Epoch: 20, Loss: 0.08493433892726898\n",
      "Epoch: 20, Loss: 0.076607346534729\n",
      "Epoch: 21, Loss: 0.04632608965039253\n",
      "Epoch: 21, Loss: 0.06976224482059479\n",
      "Epoch: 21, Loss: 0.05045555159449577\n",
      "Epoch: 21, Loss: 0.08774694800376892\n",
      "Epoch: 21, Loss: 0.11173979938030243\n",
      "Epoch: 21, Loss: 0.05568183213472366\n",
      "Epoch: 21, Loss: 0.02252916805446148\n",
      "Epoch: 21, Loss: 0.029649438336491585\n",
      "Epoch: 21, Loss: 0.13065871596336365\n",
      "Epoch: 21, Loss: 0.0837145447731018\n",
      "Epoch: 21, Loss: 0.04614055156707764\n",
      "Epoch: 21, Loss: 0.14177057147026062\n",
      "Epoch: 21, Loss: 0.13046663999557495\n",
      "Epoch: 21, Loss: 0.020326869562268257\n",
      "Epoch: 21, Loss: 0.021894654259085655\n",
      "Epoch: 22, Loss: 0.10552628338336945\n",
      "Epoch: 22, Loss: 0.12633615732192993\n",
      "Epoch: 22, Loss: 0.11416929960250854\n",
      "Epoch: 22, Loss: 0.036708980798721313\n",
      "Epoch: 22, Loss: 0.0976516455411911\n",
      "Epoch: 22, Loss: 0.04701391980051994\n",
      "Epoch: 22, Loss: 0.10810757428407669\n",
      "Epoch: 22, Loss: 0.05792459845542908\n",
      "Epoch: 22, Loss: 0.06216999143362045\n",
      "Epoch: 22, Loss: 0.09211728721857071\n",
      "Epoch: 22, Loss: 0.04838814213871956\n",
      "Epoch: 22, Loss: 0.05762604996562004\n",
      "Epoch: 22, Loss: 0.017227619886398315\n",
      "Epoch: 22, Loss: 0.049924690276384354\n",
      "Epoch: 22, Loss: 0.0012421176070347428\n",
      "Epoch: 23, Loss: 0.038292188197374344\n",
      "Epoch: 23, Loss: 0.1329212784767151\n",
      "Epoch: 23, Loss: 0.08678178489208221\n",
      "Epoch: 23, Loss: 0.05942503735423088\n",
      "Epoch: 23, Loss: 0.11717964708805084\n",
      "Epoch: 23, Loss: 0.056956082582473755\n",
      "Epoch: 23, Loss: 0.038974277675151825\n",
      "Epoch: 23, Loss: 0.11932487785816193\n",
      "Epoch: 23, Loss: 0.05041933059692383\n",
      "Epoch: 23, Loss: 0.04298880696296692\n",
      "Epoch: 23, Loss: 0.061669766902923584\n",
      "Epoch: 23, Loss: 0.05506560578942299\n",
      "Epoch: 23, Loss: 0.047580283135175705\n",
      "Epoch: 23, Loss: 0.09714321792125702\n",
      "Epoch: 23, Loss: 0.023940404877066612\n",
      "Epoch: 24, Loss: 0.035024505108594894\n",
      "Epoch: 24, Loss: 0.06573594361543655\n",
      "Epoch: 24, Loss: 0.10343495011329651\n",
      "Epoch: 24, Loss: 0.059573061764240265\n",
      "Epoch: 24, Loss: 0.07202593982219696\n",
      "Epoch: 24, Loss: 0.09816434234380722\n",
      "Epoch: 24, Loss: 0.13429959118366241\n",
      "Epoch: 24, Loss: 0.04500053822994232\n",
      "Epoch: 24, Loss: 0.11893371492624283\n",
      "Epoch: 24, Loss: 0.03921525180339813\n",
      "Epoch: 24, Loss: 0.029069693759083748\n",
      "Epoch: 24, Loss: 0.08467632532119751\n",
      "Epoch: 24, Loss: 0.06846410781145096\n",
      "Epoch: 24, Loss: 0.03841017559170723\n",
      "Epoch: 24, Loss: 0.021300574764609337\n",
      "Epoch: 25, Loss: 0.04607946425676346\n",
      "Epoch: 25, Loss: 0.04677180200815201\n",
      "Epoch: 25, Loss: 0.1390492469072342\n",
      "Epoch: 25, Loss: 0.0441010557115078\n",
      "Epoch: 25, Loss: 0.022057922556996346\n",
      "Epoch: 25, Loss: 0.08410123735666275\n",
      "Epoch: 25, Loss: 0.04994916170835495\n",
      "Epoch: 25, Loss: 0.0866774246096611\n",
      "Epoch: 25, Loss: 0.14309529960155487\n",
      "Epoch: 25, Loss: 0.040561653673648834\n",
      "Epoch: 25, Loss: 0.06440183520317078\n",
      "Epoch: 25, Loss: 0.06344679743051529\n",
      "Epoch: 25, Loss: 0.08952615410089493\n",
      "Epoch: 25, Loss: 0.0482097752392292\n",
      "Epoch: 25, Loss: 0.09335613250732422\n"
     ]
    }
   ],
   "source": [
    "# creating a training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculation\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1, 1))\n",
    "\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #  parameter update\n",
    "    optimizer.step()\n",
    "\n",
    "    # print loss in each epoch\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5418,  0.5976,  0.6116,  0.5072,  0.0875,  0.1720,  0.4633,  0.4983,\n",
       "          0.1877, -0.4402,  0.6465, -0.1085,  0.3180,  0.5328,  0.1359, -0.2760,\n",
       "         -0.0498,  0.1183, -0.1812, -0.4753,  0.5580,  0.7156,  0.5502,  0.7970,\n",
       "          0.7764,  0.2247,  0.5591,  0.5266,  0.4552,  0.1432]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3230], requires_grad=True)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50%\n"
     ]
    }
   ],
   "source": [
    "# model evaluation using test loader\n",
    "model.eval() # evaluation mode\n",
    "accuracy_list = [] # list to store accuracy\n",
    "\n",
    "with torch.no_grad(): # no gradient calculation\n",
    "  for batch_features, batch_labels in test_loader: # iterating over test loader\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "    y_pred = (y_pred > 0.5).float() # converting to 0 and 1\n",
    "\n",
    "    # calculating accuracy\n",
    "    batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item() # converting to float\n",
    "    accuracy_list.append(batch_accuracy) # appending accuracy to list\n",
    "\n",
    "# calculating overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "\n",
    "print(f'Accuracy: {overall_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
